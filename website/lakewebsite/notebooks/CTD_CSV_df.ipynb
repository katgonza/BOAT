{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5496eff-e5ee-40b2-81ea-c9525ff51aee",
   "metadata": {},
   "source": [
    "# CTD_CSV_df.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f3bac5b-f4ea-478f-823b-3ff60d27993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072f220-9bcf-4af4-baae-2249559f29e0",
   "metadata": {},
   "source": [
    "## 1: Paths you need to fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59952738-647a-4d5e-8b7c-acb2f5a9084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where all csv files of CTD data is stored\n",
    "folder_path = r\"C:\\Users\\15093\\work\\classes\\Summer 25\\Sittin on the dock of the bay\\Data\\All Data\"\n",
    "# folder where all profiles of CTD data will be stored\n",
    "output_dir = \"profiles\"\n",
    "# folder where you want to save the total processed dataframe as a csv file\n",
    "where_to_save = r'C:\\Users\\15093\\work\\classes\\Summer 25\\Sittin on the dock of the bay\\total_df.csv'\n",
    "\n",
    "# define areas: these were the areas we decided to use for our project\n",
    "    #DOC is the dock area\n",
    "    # HAR is harding cove\n",
    "    # MOR is morrison cove\n",
    "    # GLZ is glizzy cove or pike cove\n",
    "    # KEY is keystone cove\n",
    "    # LIL is a unnamed cove that is little\n",
    "    # ASP is aspen view (the parking lot near the yampa)\n",
    "    # MID is defined later in the code as anywhere that was not one of these locations (middle of stagecoach)\n",
    "polygon_coords = {\n",
    "    'DOC': [(40.28429, -106.85365), (40.28360, -106.85341), (40.28240, -106.85488), (40.28356, -106.85524)],\n",
    "    'HAR': [(40.28424, -106.85348), (40.28565, -106.85185), (40.28797, -106.85680), (40.28793, -106.85836)],\n",
    "    'MOR': [(40.28003, -106.84560), (40.28021, -106.84274), (40.27252, -106.83760), (40.27183, -106.84056)],\n",
    "    'GLZ': [(40.27291, -106.84515), (40.27610, -106.85043), (40.27509, -106.85397), (40.27129, -106.84970)],\n",
    "    'KEY': [(40.27705, -106.86361), (40.27700, -106.86697), (40.28124, -106.86839), (40.28180, -106.86597)],\n",
    "    'LIL': [(40.27265, -106.86163), (40.27315, -106.85961), (40.27114, -106.85906), (40.27115, -106.86068)],\n",
    "    'ASP': [(40.272286, -106.876870),(40.272286, -106.876599),(40.272016, -106.876599),(40.272016, -106.876870)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e7f2d-f49f-4474-b419-3d33ffc66fd0",
   "metadata": {},
   "source": [
    "## 2: Run this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3061fa66-995f-43f4-bef2-98606461fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    # Step 1: Read header lines (first 29 lines)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        header_lines = [next(f) for _ in range(29)]\n",
    "\n",
    "#collect the meta data\n",
    "    meta = {}\n",
    "    for line in header_lines:\n",
    "        line = line.strip()\n",
    "        if not line.startswith('%'):\n",
    "            continue\n",
    "        line = line.lstrip('%').strip()\n",
    "    \n",
    "        if not line or ',' not in line:\n",
    "            continue  # skip empty or malformed lines\n",
    "    \n",
    "        key, value = line.split(',', 1)\n",
    "        meta[key.strip()] = value.strip()\n",
    "\n",
    "#skip invaliid measurement files\n",
    "    if meta.get(\"Sample type\", \"\").lower() == \"invalid\":\n",
    "        continue\n",
    "\n",
    "    latitude = float(meta.get(\"Start latitude\", \"nan\"))\n",
    "    longitude = float(meta.get(\"Start longitude\", \"nan\"))\n",
    "    utc_time = pd.to_datetime(meta.get(\"Cast time (UTC)\", pd.NaT))\n",
    "    device_id = meta.get(\"Device\", \"\")\n",
    "    file_name = meta.get(\"File name\", \"\")\n",
    "    cast_duration = float(meta.get(\"Cast duration (Seconds)\", \"nan\"))\n",
    "    samples_per_sec = float(meta.get(\"Samples per second\", \"nan\"))\n",
    "    \n",
    "    try:\n",
    "        data = np.genfromtxt(file_path, delimiter=',', skip_header=29)\n",
    "        if data.ndim == 1:\n",
    "            data = data.reshape(1, -1)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    df.columns = [\"Pressure (dbar)\", \"Depth (m)\", \"Temperature (°C)\", \"Conductivity (µS/cm)\", \n",
    "                  \"Specific Conductance (µS/cm)\", \"Salinity (PSS)\", \n",
    "                  \"Sound Velocity (m/s)\", \"Density (kg/m³)\"]\n",
    "    \n",
    "    # Step 6: Add metadata columns\n",
    "    df[\"Latitude\"] = latitude\n",
    "    df[\"Longitude\"] = longitude\n",
    "    df[\"UTC Time\"] = utc_time\n",
    "    df[\"File Name\"] = file_name\n",
    "\n",
    "    # Step 7: Append to list\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# concat all dataframes\n",
    "total_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Extract the first row for each cast (based on File Name)\n",
    "cast_locations = total_df.groupby(\"File Name\").first().reset_index()\n",
    "\n",
    "cast_locations = cast_locations[[\"Latitude\", \"Longitude\", \"File Name\"]]\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "grouped_meas = total_df.groupby('File Name')\n",
    "\n",
    "# We'll collect all data into a list of dicts\n",
    "image_data = []\n",
    "\n",
    "for date, group in grouped_meas:\n",
    "    group = group.sort_values(by='Depth (m)') \n",
    "\n",
    "    # Determine test type based on number of depth values\n",
    "    test_type = \"point\" if group['Depth (m)'].nunique() <= 1 else \"cast\"\n",
    "\n",
    "    if test_type == \"cast\":\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 6), sharey=True)\n",
    "        fig.suptitle(f'Profiles on {date}', fontsize=36)\n",
    "\n",
    "        axs[0].plot(group['Temperature (°C)'], group['Depth (m)'])\n",
    "        axs[0].set_xlabel('Temperature (°C)', fontsize=24, fontweight='bold')\n",
    "        axs[0].set_ylabel('Depth (m)', fontsize=24, fontweight='bold')\n",
    "        axs[0].invert_yaxis()\n",
    "\n",
    "        axs[1].plot(group['Conductivity (µS/cm)'], group['Depth (m)'])\n",
    "        axs[1].set_xlabel('Conductivity (µS/cm)', fontsize=24, fontweight='bold')\n",
    "\n",
    "        axs[2].plot(group['Salinity (PSS)'], group['Depth (m)'])\n",
    "        axs[2].set_xlabel('Salinity (PSS)', fontsize=24, fontweight='bold')\n",
    "\n",
    "        axs[3].plot(group['Density (kg/m³)'], group['Depth (m)'])\n",
    "        axs[3].set_xlabel('Density (kg/m³)', fontsize=24, fontweight='bold')\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.tick_params(axis='both', labelsize=16)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        img_path = os.path.join(output_dir, f\"profile_{date}.png\")\n",
    "        fig.savefig(img_path)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        img_path = None  # No image for point measurement\n",
    "\n",
    "    # Store info\n",
    "    image_data.append({\n",
    "        'File Name': date,\n",
    "        'Latitude': group.iloc[0]['Latitude'],\n",
    "        'Longitude': group.iloc[0]['Longitude'],\n",
    "        'ImagePath': img_path,\n",
    "        'TestType': test_type,\n",
    "        'Temperature (°C)': group['Temperature (°C)'].iloc[0],\n",
    "        'Conductivity (µS/cm)': group['Conductivity (µS/cm)'].iloc[0],\n",
    "        'Salinity (PSS)': group['Salinity (PSS)'].iloc[0],\n",
    "        'Density (kg/m³)': group['Density (kg/m³)'].iloc[0],\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "image_df = pd.DataFrame(image_data)\n",
    "# Merge 'TestType' from cast_locations into total_df based on 'File Name'\n",
    "cast_locations['TestType'] = image_df['TestType']\n",
    "cast_locations['ImagePath'] = image_df['ImagePath']\n",
    "total_df = total_df.merge(cast_locations[['File Name', 'TestType']], on='File Name', how='left')    \n",
    "total_df = total_df.merge(cast_locations[['File Name', 'ImagePath']], on='File Name', how='left') \n",
    "\n",
    "polygons = {name: Polygon(coords) for name, coords in polygon_coords.items()}\n",
    "\n",
    "# ---- Classify Points by Area ----\n",
    "def get_area(lat, lon):\n",
    "    point = Point(lat, lon)\n",
    "    for name, poly in polygons.items():\n",
    "        if poly.contains(point):\n",
    "            return name\n",
    "    return 'MID'\n",
    "\n",
    "cast_locations['Area'] = cast_locations.apply(lambda row: get_area(row['Latitude'], row['Longitude']), axis=1)\n",
    "total_df['Area'] = total_df.apply(lambda row: get_area(row['Latitude'], row['Longitude']), axis=1)\n",
    "cast_locations['Date'] = pd.to_datetime(cast_locations['File Name'].str.extract(r'_(\\d{8})_')[0], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe3c96-e5e5-4cf5-8bfb-911d90728f8f",
   "metadata": {},
   "source": [
    "## 3: Preview DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0377d53-adb5-4c92-bf02-2a8c19e2921a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pressure (dbar)</th>\n",
       "      <th>Depth (m)</th>\n",
       "      <th>Temperature (°C)</th>\n",
       "      <th>Conductivity (µS/cm)</th>\n",
       "      <th>Specific Conductance (µS/cm)</th>\n",
       "      <th>Salinity (PSS)</th>\n",
       "      <th>Sound Velocity (m/s)</th>\n",
       "      <th>Density (kg/m³)</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>UTC Time</th>\n",
       "      <th>File Name</th>\n",
       "      <th>TestType</th>\n",
       "      <th>ImagePath</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.153151</td>\n",
       "      <td>9.153524</td>\n",
       "      <td>296.339874</td>\n",
       "      <td>433.834991</td>\n",
       "      <td>0.204679</td>\n",
       "      <td>1444.146359</td>\n",
       "      <td>999.934361</td>\n",
       "      <td>40.274148</td>\n",
       "      <td>-106.8399</td>\n",
       "      <td>2025-05-13 18:12:11</td>\n",
       "      <td>CC2435009_20250513_181211</td>\n",
       "      <td>cast</td>\n",
       "      <td>profiles\\profile_CC2435009_20250513_181211.png</td>\n",
       "      <td>MOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.458792</td>\n",
       "      <td>9.255136</td>\n",
       "      <td>295.835466</td>\n",
       "      <td>431.811837</td>\n",
       "      <td>0.203774</td>\n",
       "      <td>1444.561198</td>\n",
       "      <td>999.927172</td>\n",
       "      <td>40.274148</td>\n",
       "      <td>-106.8399</td>\n",
       "      <td>2025-05-13 18:12:11</td>\n",
       "      <td>CC2435009_20250513_181211</td>\n",
       "      <td>cast</td>\n",
       "      <td>profiles\\profile_CC2435009_20250513_181211.png</td>\n",
       "      <td>MOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.764653</td>\n",
       "      <td>9.132318</td>\n",
       "      <td>295.647002</td>\n",
       "      <td>433.089545</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>1444.069489</td>\n",
       "      <td>999.938574</td>\n",
       "      <td>40.274148</td>\n",
       "      <td>-106.8399</td>\n",
       "      <td>2025-05-13 18:12:11</td>\n",
       "      <td>CC2435009_20250513_181211</td>\n",
       "      <td>cast</td>\n",
       "      <td>profiles\\profile_CC2435009_20250513_181211.png</td>\n",
       "      <td>MOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.05</td>\n",
       "      <td>1.070511</td>\n",
       "      <td>9.033097</td>\n",
       "      <td>296.121842</td>\n",
       "      <td>435.049797</td>\n",
       "      <td>0.205173</td>\n",
       "      <td>1443.672646</td>\n",
       "      <td>999.948268</td>\n",
       "      <td>40.274148</td>\n",
       "      <td>-106.8399</td>\n",
       "      <td>2025-05-13 18:12:11</td>\n",
       "      <td>CC2435009_20250513_181211</td>\n",
       "      <td>cast</td>\n",
       "      <td>profiles\\profile_CC2435009_20250513_181211.png</td>\n",
       "      <td>MOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.35</td>\n",
       "      <td>1.376366</td>\n",
       "      <td>8.925369</td>\n",
       "      <td>296.570547</td>\n",
       "      <td>437.092585</td>\n",
       "      <td>0.206079</td>\n",
       "      <td>1443.240202</td>\n",
       "      <td>999.958485</td>\n",
       "      <td>40.274148</td>\n",
       "      <td>-106.8399</td>\n",
       "      <td>2025-05-13 18:12:11</td>\n",
       "      <td>CC2435009_20250513_181211</td>\n",
       "      <td>cast</td>\n",
       "      <td>profiles\\profile_CC2435009_20250513_181211.png</td>\n",
       "      <td>MOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pressure (dbar)  Depth (m)  Temperature (°C)  Conductivity (µS/cm)  \\\n",
       "0             0.15   0.153151          9.153524            296.339874   \n",
       "1             0.45   0.458792          9.255136            295.835466   \n",
       "2             0.75   0.764653          9.132318            295.647002   \n",
       "3             1.05   1.070511          9.033097            296.121842   \n",
       "4             1.35   1.376366          8.925369            296.570547   \n",
       "\n",
       "   Specific Conductance (µS/cm)  Salinity (PSS)  Sound Velocity (m/s)  \\\n",
       "0                    433.834991        0.204679           1444.146359   \n",
       "1                    431.811837        0.203774           1444.561198   \n",
       "2                    433.089545        0.204300           1444.069489   \n",
       "3                    435.049797        0.205173           1443.672646   \n",
       "4                    437.092585        0.206079           1443.240202   \n",
       "\n",
       "   Density (kg/m³)   Latitude  Longitude            UTC Time  \\\n",
       "0       999.934361  40.274148  -106.8399 2025-05-13 18:12:11   \n",
       "1       999.927172  40.274148  -106.8399 2025-05-13 18:12:11   \n",
       "2       999.938574  40.274148  -106.8399 2025-05-13 18:12:11   \n",
       "3       999.948268  40.274148  -106.8399 2025-05-13 18:12:11   \n",
       "4       999.958485  40.274148  -106.8399 2025-05-13 18:12:11   \n",
       "\n",
       "                   File Name TestType  \\\n",
       "0  CC2435009_20250513_181211     cast   \n",
       "1  CC2435009_20250513_181211     cast   \n",
       "2  CC2435009_20250513_181211     cast   \n",
       "3  CC2435009_20250513_181211     cast   \n",
       "4  CC2435009_20250513_181211     cast   \n",
       "\n",
       "                                        ImagePath Area  \n",
       "0  profiles\\profile_CC2435009_20250513_181211.png  MOR  \n",
       "1  profiles\\profile_CC2435009_20250513_181211.png  MOR  \n",
       "2  profiles\\profile_CC2435009_20250513_181211.png  MOR  \n",
       "3  profiles\\profile_CC2435009_20250513_181211.png  MOR  \n",
       "4  profiles\\profile_CC2435009_20250513_181211.png  MOR  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1d4a1-0c31-45c4-8253-9bd3b3fba656",
   "metadata": {},
   "source": [
    "## 4: Save DataFrame as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c874e51d-2296-4910-ac49-57d8f0f776e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv(where_to_save, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
