Traceback (most recent call last):
  File "C:\Users\14027\anaconda3\Lib\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\14027\anaconda3\Lib\site-packages\nbclient\client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\14027\anaconda3\Lib\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\14027\anaconda3\Lib\asyncio\base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\14027\anaconda3\Lib\site-packages\nbclient\client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "C:\Users\14027\anaconda3\Lib\site-packages\nbclient\client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\14027\anaconda3\Lib\site-packages\nbclient\client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
file_paths = glob.glob(os.path.join(folder_path, "*.csv"))

all_dfs = []

for file_path in file_paths:
    # Step 1: Read header lines (first 29 lines)
    with open(file_path, 'r', encoding='utf-8') as f:
        header_lines = [next(f) for _ in range(29)]

#collect the meta data
    meta = {}
    for line in header_lines:
        line = line.strip()
        if not line.startswith('%'):
            continue
        line = line.lstrip('%').strip()
    
        if not line or ',' not in line:
            continue  # skip empty or malformed lines
    
        key, value = line.split(',', 1)
        meta[key.strip()] = value.strip()

#skip invaliid measurement files
    if meta.get("Sample type", "").lower() == "invalid":
        continue

    latitude = float(meta.get("Start latitude", "nan"))
    longitude = float(meta.get("Start longitude", "nan"))
    utc_time = pd.to_datetime(meta.get("Cast time (UTC)", pd.NaT))
    device_id = meta.get("Device", "")
    file_name = meta.get("File name", "")
    cast_duration = float(meta.get("Cast duration (Seconds)", "nan"))
    samples_per_sec = float(meta.get("Samples per second", "nan"))
    
    try:
        data = np.genfromtxt(file_path, delimiter=',', skip_header=29)
        if data.ndim == 1:
            data = data.reshape(1, -1)
    except Exception as e:
        continue
        
    df = pd.DataFrame(data)
    
    df.columns = ["Pressure (dbar)", "Depth (m)", "Temperature (Â°C)", "Conductivity (ÂµS/cm)", 
                  "Specific Conductance (ÂµS/cm)", "Salinity (PSS)", 
                  "Sound Velocity (m/s)", "Density (kg/mÂ³)"]
    
    # Step 6: Add metadata columns
    df["Latitude"] = latitude
    df["Longitude"] = longitude
    df["UTC Time"] = utc_time
    df["File Name"] = file_name

    # Step 7: Append to list
    all_dfs.append(df)

# concat all dataframes
total_df = pd.concat(all_dfs, ignore_index=True)

# Extract the first row for each cast (based on File Name)
cast_locations = total_df.groupby("File Name").first().reset_index()

cast_locations = cast_locations[["Latitude", "Longitude", "File Name"]]

os.makedirs(output_dir, exist_ok=True)

grouped_meas = total_df.groupby('File Name')

# We'll collect all data into a list of dicts
image_data = []

for date, group in grouped_meas:
    group = group.sort_values(by='Depth (m)') 

    # Determine test type based on number of depth values
    test_type = "point" if group['Depth (m)'].nunique() <= 1 else "cast"

    if test_type == "cast":
        fig, axs = plt.subplots(1, 4, figsize=(20, 6), sharey=True)
        fig.suptitle(f'Profiles on {date}', fontsize=36)

        axs[0].plot(group['Temperature (Â°C)'], group['Depth (m)'])
        axs[0].set_xlabel('Temperature (Â°C)', fontsize=24, fontweight='bold')
        axs[0].set_ylabel('Depth (m)', fontsize=24, fontweight='bold')
        axs[0].invert_yaxis()

        axs[1].plot(group['Conductivity (ÂµS/cm)'], group['Depth (m)'])
        axs[1].set_xlabel('Conductivity (ÂµS/cm)', fontsize=24, fontweight='bold')

        axs[2].plot(group['Salinity (PSS)'], group['Depth (m)'])
        axs[2].set_xlabel('Salinity (PSS)', fontsize=24, fontweight='bold')

        axs[3].plot(group['Density (kg/mÂ³)'], group['Depth (m)'])
        axs[3].set_xlabel('Density (kg/mÂ³)', fontsize=24, fontweight='bold')

        for ax in axs:
            ax.tick_params(axis='both', labelsize=16)

        plt.tight_layout()

        img_path = os.path.join(output_dir, f"profile_{date}.png")
        fig.savefig(img_path)
        plt.close(fig)
    else:
        img_path = None  # No image for point measurement

    # Store info
    image_data.append({
        'File Name': date,
        'Latitude': group.iloc[0]['Latitude'],
        'Longitude': group.iloc[0]['Longitude'],
        'ImagePath': img_path,
        'TestType': test_type,
        'Temperature (Â°C)': group['Temperature (Â°C)'].iloc[0],
        'Conductivity (ÂµS/cm)': group['Conductivity (ÂµS/cm)'].iloc[0],
        'Salinity (PSS)': group['Salinity (PSS)'].iloc[0],
        'Density (kg/mÂ³)': group['Density (kg/mÂ³)'].iloc[0],
    })

# Create DataFrame
image_df = pd.DataFrame(image_data)
# Merge 'TestType' from cast_locations into total_df based on 'File Name'
cast_locations['TestType'] = image_df['TestType']
cast_locations['ImagePath'] = image_df['ImagePath']
total_df = total_df.merge(cast_locations[['File Name', 'TestType']], on='File Name', how='left')    
total_df = total_df.merge(cast_locations[['File Name', 'ImagePath']], on='File Name', how='left') 

polygons = {name: Polygon(coords) for name, coords in polygon_coords.items()}

# ---- Classify Points by Area ----
def get_area(lat, lon):
    point = Point(lat, lon)
    for name, poly in polygons.items():
        if poly.contains(point):
            return name
    return 'MID'

cast_locations['Area'] = cast_locations.apply(lambda row: get_area(row['Latitude'], row['Longitude']), axis=1)
total_df['Area'] = total_df.apply(lambda row: get_area(row['Latitude'], row['Longitude']), axis=1)
cast_locations['Date'] = pd.to_datetime(cast_locations['File Name'].str.extract(r'_(\d{8})_')[0], format='%Y%m%d')
------------------


[1;31m---------------------------------------------------------------------------[0m
[1;31mNameError[0m                                 Traceback (most recent call last)
Cell [1;32mIn[3], line 1[0m
[1;32m----> 1[0m file_paths [38;5;241m=[39m glob[38;5;241m.[39mglob(os[38;5;241m.[39mpath[38;5;241m.[39mjoin(folder_path, [38;5;124m"[39m[38;5;124m*.csv[39m[38;5;124m"[39m))
[0;32m      3[0m all_dfs [38;5;241m=[39m []
[0;32m      5[0m [38;5;28;01mfor[39;00m file_path [38;5;129;01min[39;00m file_paths:
[0;32m      6[0m     [38;5;66;03m# Step 1: Read header lines (first 29 lines)[39;00m

[1;31mNameError[0m: name 'glob' is not defined

